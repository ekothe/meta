---
title: "CompileR"
output: html_document
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
bibliography: R-Pckgs.bib
nocite: |
  @*
---

```{r settings}
dat_comp <- read.csv("data.csv")
```

```{r setup, include=FALSE}
library(metafor)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

This script demonstrates the method for assessembling SMDs described by Wolfgang Viechtbauer at http://metafor-project.org/doku.php/tips:assembling_data_smd. The comparable method for Odds Ratios is available here: http://metafor-project.org/doku.php/tips:assembling_data_or 

If you are working with other data types or have different pieces of information about studies available you may find the package 'compute.es' helpful.

## Load packages

```{r warning=FALSE, message=FALSE}
library(metafor)
library(knitr)
```

## First we make ourselves an imcomplete dataset to work with [^1]
```{r}
dat_comp$X <- NULL
dat_comp$dval <- with(dat_comp, (Intervention.Mean - Control.Mean) / sqrt(((Intervention.N-1)*Intervention.SD^2 + (Control.N-1)*Control.SD^2)/(Intervention.N + Control.N - 2)))
dat_comp$tval <- with(dat_comp, dval / sqrt(1/Intervention.N + 1/Control.N))
dat_comp$pval <- 2 * with(dat_comp, pt(abs(tval), df = Intervention.N + Control.N - 2, lower.tail=FALSE))
dat_comp$sign <- with(dat_comp, ifelse(Intervention.Mean > Control.Mean, 1, -1))
dat_comp[,c("dval","tval","pval")] <- round(dat_comp[,c("dval","tval","pval")], 2)
dat_comp[c(1,7),c("Intervention.Mean","Intervention.SD","Control.Mean","Control.SD","tval","pval","sign")] <- NA
dat_comp[c(5,8),c("Intervention.Mean","Intervention.SD","Control.Mean","Control.SD", "dval","pval","sign")] <- NA
dat_comp[c(2),c("Intervention.Mean","Intervention.SD","Control.Mean","Control.SD", "dval","pval")]    <- NA
dat_comp[c(3,4,6),c("dval", "pval", "tval", "sign")] <- NA
```

`r kable(dat_comp)`

## Let's compile!

### Start by calculating what we can
```{r}
dat_comp <- escalc(measure="SMD", m1i=Intervention.Mean, sd1i=Intervention.SD, n1i=Intervention.N, m2i=Control.Mean,  sd2i=Control.SD, n2i=Control.N, data=dat_comp)
```
`r kable(dat_comp)`

### Try and calculate t-values from available exact p-values [^2]
```{r}
dat_comp$tval <- replmiss(dat_comp$tval, with(dat_comp, sign * qt(pval/2, df=Intervention.N+Control.N-2, lower.tail=FALSE)))
```
`r kable(dat_comp)`

## Try and calculate d-values from available t-values
```{r}
dat_comp$dval <- replmiss(dat_comp$dval, with(dat_comp, tval * sqrt(1/Intervention.N + 1/Control.N)))
```
`r kable(dat_comp)`

### Convert from Cohen's d to hedges g
```{r}
dat_comp$yi <- replmiss(dat_comp$yi, with(dat_comp, (1 - 3/(4*(Intervention.N+Control.N-2) - 1)) * dval))
```
`r kable(dat_comp)`

### Calculate missing sampling variances
```{r}
dat_comp$vi <- replmiss(dat_comp$vi, with(dat_comp, 1/Intervention.N+ 1/Control.N + yi^2/(2*(Intervention.N+Control.N))))
```
`r kable(dat_comp)`

## Write the data to a file
```{r}
write.csv(dat_comp, "compiled_data.csv")
```

[^1]: Obviously you don't need to complete this step when working with real data
[^2]: If exact p values are not availble, one possible approach is to use the reported p cut off for the statistic (e.g. p<0.05) would use the p value 0.05. This is very conservative but may be preferrable to excluding the study entirely

## Packages used in this document
```{r include=FALSE}
citPkgs <- names(sessionInfo()$otherPkgs)
write_bib(citPkgs, file="R-Pckgs.bib")
```

